{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CÓDIGO PYTHON WEMOB.\n",
    "\n",
    "El objetivo del siguiente código es recoger la depuración realizada en notebook anterior (que da como resultado un archivo .csv denominado wemob) que contiene todos los timestamp facilitados por WEMOB que pasaron dicho filtro (Notebook : TFMwemob1), y que ahora comenzaremos a sintetizar para conseguir unos datasets que permitan los procesos posteriores : EVALUACIÓN RUTAS MÁS REPETIDAS, ALIMENTACIÓN ALGORITMO PREDICTIVO DEL CONSUMO DE LAS MISMAS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos las diferentes librerias que vamos a necesitar.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import glob\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from datetime import timedelta,datetime\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import gc\n",
    "\n",
    "# Para permitir ver todas las columnas/filas posibles, que permitan diseccionar los diferentes datasets resultantes\n",
    "# a la busqueda de posibles errores o malas interpretaciones.\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos paquete que se nos solicita en Cloud.\n",
    "\n",
    "pip install gcsfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primer contador.\n",
    "\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Secuencia tareas a realizar:\n",
    "\n",
    "    A) Creación dataset (DESARROLLO RUTAS), que aglutinará el detalle del desarrollo de las mismas en función de su      \n",
    "    agrupamiento (dependiendo de la situación).\n",
    "    \n",
    "    Situaciones: 1 (Paro total, no hay velocidad no hay revoluciones por minuto).\n",
    "                 2 (Paro a ralentí, no hay velocidad pero si revoluciones por minuto para mantener refrigerada la caja).\n",
    "                 3 (En ruta, hay velocidad y por tanto entendemos que el camión está en movimiento).\n",
    "                 \n",
    "    B) Una vez tenemos reducidos los registros del dataset original, en función de su situación.....identificamos las rutas.\n",
    "\n",
    "    El parámetro más importante es la duración de la parada (ya sea total o al ralentí), en este caso vamos a establecer           mayor o igual a una hora, pero hemos de tener en cuenta que si ampliamos dicha duración las rutas se reducirán                 ostensiblemente (dependiente de la duración que se estime).\n",
    "\n",
    "    Ejemplo, para una ruta su timestamp de incio será el TMPc del estado y su timestamp final será el TMPa del estado.\n",
    "\n",
    "    Nos aseguramos que las columnas TMPa y TMPc tienen valor datetime, y salvo las variables catalogadas como float el resto       se convierten en integer, manteniendo el mismo criterio que en la depuración para optimizar al máximo el rendimiento           computacional.\n",
    "\n",
    "    Añadimos al dataframe una columna que será la diferencia de fechas, evaluada en horas.El resultado sería una nueva             columna tipo timedelta, y la convertimos a float.\n",
    "    \n",
    "    C) Este código, lo que hace es relacionar cada ruta definida en RUTAS con su secuencia de desarrollo en M2                     (DESARROLLO_RUTAS), estableciendo como campo de enlace NRUTA (idéntico en ambos dataset) con la intencion de poder             establecer consultas a futuro.\n",
    "    \n",
    "    D) Se carga la librería GEOPY con objeto de establecer (en función de la latitud/longitud), el código postal/comunidad/pais \n",
    "    de todas y cada una de las lineas contenidas en el dataset RUTAS. Esta parte del código tiene un consumo computaciones de       unas 8 hrs, debido a las rutas identificadas.\n",
    "    \n",
    "    E) Agrupando el dataset RUTAS por variables de salida y llegada, se establece un ranking (rutas más habituales) que se         almacenará en el dataset MRUTAS.\n",
    "    \n",
    "    F) El objetivo será crear un dataset (MAESTRO_RUTAS general) que sintetice desarrollo de rutas (M2) en una sola ruta, por       matricula y donde las variables resultantes sean promedios o diferencias en función de la naturaleza de las mismas. Este       dataset simplifica y concentra la información con objeto de poderse modelizar de una forma más eficiente.\n",
    "    \n",
    "    G) En este caso, el dataset resultante (MAESTRO_RUTAS x conductor) tiene la misma finalidad pero incluyendo los datos           particulares de los diferentes conductores que hayan sido asignados a las rutas."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Inicio con Cloud. Todo el proceso anterior se concentra en un archivo csv generado con anterioridad (notebook Jesús). Que ahora leemos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leemos csv reseñado al inicio, producto de depuración procesada por notebook TFMwemob1.\n",
    "\n",
    "M2 = pd.read_csv('wemob.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Borramos la columna de exceso.\n",
    "\n",
    "del(M2['Unnamed: 0'])\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Lo ordenamos con \"implace\" true para que se ordene el propio objeto. Con lo que se evita aumentar la memoria consumida por el programa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "M2.sort_values(['MatriculaNum','Timestamp'], inplace=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Y reseteamos los indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M2 = M2.reset_index()\n",
    "del M2['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nos aseguramos que Timestamp tiene formato datetime\n",
    "M2['Timestamp'] = pd.to_datetime(M2['Timestamp'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Aquí comenzamos los códigos de transformación. Vemos la composición del dataset final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "M2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TAREA (A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo es reducir el número de registros del dataset inicial, en función de la situación (parada total - cuando velocidad es cero y las rpm también - / parada ralentí - cuando velocidad es cero y las rpm no lo son - / parada total - cuando el transporte está en marcha ) y los diferentes timestamp consecutivos que cumplen las mismas condiciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M2['CS']=0\n",
    "\n",
    "# Renombramos columnas del dataset resultante.\n",
    "M2.rename(columns={'Latitud':'LATa', 'Longitud':'LONGa', 'Altitud':'ALTa', 'Odometro':'ODOa', 'Velocidad':'VELCa',\\\n",
    "'HorasMotor':'HMa','ControlCrucero':'CCa', 'TemperaturaMotor':'TMa', 'RPM':'RPMa', 'NivelFuel':'NFa','ConsumoTotal':'CTa',\\\n",
    "'Frenadas':'FRNa', 'TiempoRalenti':'TRa', 'ParMotor':'PMa', 'Pedal':'PDLa','Embrague':'EMBa', 'ConductorNum':'COND',\\\n",
    "'MatriculaNum':'MTR', 'Timestamp':'TMPa'},inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos las variables faltantes.\n",
    "\n",
    "M2['SEC']= M2.index\n",
    "M2['NRUTA']=0\n",
    "M2['POSICION']=0\n",
    "M2['LATc']= M2['LATa']\n",
    "M2['LONGc']= M2['LONGa']\n",
    "M2['ALTc']= M2['ALTa']\n",
    "M2['ODOc']= M2['ODOa']\n",
    "M2['VELCc']= M2['VELCa']\n",
    "M2['HMc']= M2['HMa']\n",
    "M2['CCc']= M2['CCa']\n",
    "M2['TMc']= M2['TMa']\n",
    "M2['RPMc']= M2['RPMa']\n",
    "M2['NFc']= M2['NFa']\n",
    "M2['CTc']= M2['CTa']\n",
    "M2['FRNc']= M2['FRNa']\n",
    "M2['TRc']= M2['TRa']\n",
    "M2['PMc']= M2['PMa']\n",
    "M2['PDLc']= M2['PDLa']\n",
    "M2['EMBc']= M2['EMBa']\n",
    "M2['TMPc']= M2['TMPa']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reordenamos todas las columnas.\n",
    "M2 = M2[['SEC','NRUTA','POSICION','MTR','CS','LATa','LATc','LONGa','LONGc','TMPa','TMPc','COND','ALTa',\\\n",
    "                           'ALTc','ODOa','ODOc','VELCa','VELCc','HMa','HMc','CCa','CCc','TMa','TMc','RPMa','RPMc','NFa',\\\n",
    "                           'NFc','CTa','CTc','FRNa','FRNc','TRa','TRc','PMa','PMc','PDLa','PDLc','EMBa','EMBc']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establecemos registros tipo 1-2-3\n",
    "\n",
    "M2.loc[M2.RPMa == 0, ['CS']] = 1\n",
    "M2.loc[M2.RPMa != 0, ['CS']] = 2\n",
    "M2.loc[M2.VELCa != 0, ['CS']] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establecemos indice para aglutinar registros. En este caso utilizaremos latitud y longitud,\n",
    "# como es lógico son diferentes en cada estado.\n",
    "GBcs0 = M2.groupby( [ 'LATa', 'LONGa','ODOa','CS','MTR','COND'] )\n",
    "\n",
    "# Variables iniciales.\n",
    "cols = ['SEC']\n",
    "\n",
    "for c in cols:\n",
    "    M2[c] = GBcs0[c].transform(\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aglutinamos entonces.\n",
    "\n",
    "GBcs0 = M2.groupby( ['SEC'] )\n",
    "\n",
    "# Variables iniciales.\n",
    "cols = ['MTR','CS','LATa','LONGa','TMPa','COND','ALTa','ODOa', 'VELCa', 'HMa','CCa', 'TMa', 'RPMa','NFa','CTa', 'FRNa','TRa', 'PMa','PDLa', 'EMBa']\n",
    "for c in cols:\n",
    "    M2[c] = GBcs0[c].transform(\"first\")\n",
    "\n",
    "# Variables finales\n",
    "cols = ['LATc','LONGc','TMPc','ALTc','ODOc', 'VELCc', 'HMc','CCc', 'TMc', 'RPMc','NFc','CTc','FRNc','TRc', 'PMc','PDLc', 'EMBc']\n",
    "for c in cols:\n",
    "    M2[c] = GBcs0[c].transform(\"last\")\n",
    "\n",
    "# Realizamos la primera depuración.\n",
    "\n",
    "M2= M2.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M2.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "En este punto creamos un dataset que contiene unicamente el valor de la variable TMPc (fecha/hora conclusión), y que posteriormente se utilizará para calcular el tiempo cronologico que hay entre el final de una linea y la siguente. Esa variable se denominará TMPx."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = M2[['TMPc']]\n",
    "df.rename(columns={'TMPc': 'TMPx'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos la primera linea para que luego cuando se proceda con el merge (uniendo M2/df) podamos emparejar las variables\n",
    "# correctar para calcular TMPx\n",
    "\n",
    "M2 = M2.drop([0],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M2 = M2.reset_index()\n",
    "del M2['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index()\n",
    "del df['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M2.to_csv('M2.csv')\n",
    "df.to_csv('df.csv')\n",
    "print ('Proceso concluido')\n",
    "gc.collect()\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea (B)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "En la linea siguente, unimos el dataframe df con el objetivo anteriormente descrito."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M2 = pd.merge(M2, df, right_index=True, left_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordenamos el dataset RUTAS y DESARROLLO_RUTAS (M2), para asegurar que el código asigna rutas correctamente\n",
    "M2.sort_values(['MTR','TMPc'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M2['days']= M2['TMPc']-M2['TMPa']\n",
    "M2['S']= M2['TMPa']-M2['TMPx']\n",
    "\n",
    "# Creamos una variable que coniene el tiempo de desarrollo de esa linea (se utilizará para la identificación de rutas).\n",
    "\n",
    "M2['TIME_HRS'] = M2['days'] / np.timedelta64(1, 'h')\n",
    "\n",
    "# Creamos una variable que contiene el tiempo cronologico entre linea y linea (se utilizará para la identificación de rutas).\n",
    "\n",
    "M2['DELAYED'] = M2['S']/np.timedelta64(1, 'h')\n",
    "\n",
    "del(M2['days'])\n",
    "del(M2['SEC'])\n",
    "del(M2['S'])\n",
    "del(M2['TMPx'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iniciamos la identificación de rutas. Pero antes vamos a ordenar por matricua y primer timestamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el dataset Rutas\n",
    "\n",
    "RUTAS = pd.DataFrame(columns=('MTR','LATorigen','LONGorigen','LATdestino','LONGdestino','FECHA_HORAsalida','FECHA_HORAllegada',\\\n",
    "                              'DIRECCsalida','DIRECCllegada','LATLONGs','LATLONGll','NRUTA','DCRUTA'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DC = 0\n",
    "A = 0\n",
    "Iord = 0 # Esta variable controlará la elección de filas del dataframe.\n",
    "Tr = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################### COMIENZO ANALISIS\n",
    "# PUESTA EN MARCHA\n",
    "# Nos ponemos en marcha. Le damos un valor a las variables de control iniciales.\n",
    "\n",
    "if M2.iloc[Iord,3] <3:\n",
    "    \n",
    "    MATa = M2.iloc[Iord,2]\n",
    "    TMPa = M2.iloc[Iord,9]\n",
    "    LATa = M2.iloc[Iord,5]\n",
    "    LONGa = M2.iloc[Iord,7]\n",
    "else:\n",
    "    MATa = M2.iloc[Iord,2]\n",
    "    TMPa = M2.iloc[Iord,8]\n",
    "    LATa = M2.iloc[Iord,4]\n",
    "    LONGa = M2.iloc[Iord,6]\n",
    "    \n",
    "    \n",
    "# COMIENZA EL CODIGO\n",
    "\n",
    "while Tr <= len(M2.index):\n",
    "\n",
    "# CONTROL MATRICULA\n",
    "\n",
    "# Si es el primer registro saltamos todo el código\n",
    "    if A == 0:\n",
    "        A = A + 1\n",
    "        DC = 1\n",
    "\n",
    "# Si las matriculas no coinciden, estaremos ante un registro impar y deberemos resetear el sistema.\n",
    "\n",
    "    if (M2.iloc[Iord,2] != MATa) and DC == 0:\n",
    "        \n",
    "        # Retrocedemos una linea.\n",
    "        \n",
    "        Iord = Iord - 1\n",
    "        \n",
    "        # ANTES DEBEMOS GRABAR RUTA FINAL\n",
    "        RUTAS=RUTAS.append({'MTR' : MATa , 'FECHA_HORAsalida' : TMPa , 'LATorigen' : LATa ,'LONGorigen' : LONGa ,\\\n",
    "        'FECHA_HORAllegada' : M2.iloc[Iord,9] , 'LATdestino' : M2.iloc[Iord,5],'LONGdestino' : M2.iloc[Iord,7],\\\n",
    "        'DIRECCsalida' : '','DIRECCllegada' : '','LATLONGs' : '','LATLONGll' : '','NRUTA' : 0,'DCRUTA' : 0 } ,\\\n",
    "        ignore_index=True) \n",
    "       \n",
    "        # RESETEAMOS VARIABLES\n",
    "        \n",
    "        # Nos ubicamos en la línea siguiente.\n",
    "        \n",
    "        Iord = Iord + 1\n",
    "        \n",
    "        if M2.iloc[Iord,3] <3:\n",
    "    \n",
    "            MATa = M2.iloc[Iord,2]\n",
    "            TMPa = M2.iloc[Iord,9]\n",
    "            LATa = M2.iloc[Iord,5]\n",
    "            LONGa = M2.iloc[Iord,7]\n",
    "        else:\n",
    "            MATa = M2.iloc[Iord,2]\n",
    "            TMPa = M2.iloc[Iord,8]\n",
    "            LATa = M2.iloc[Iord,4]\n",
    "            LONGa = M2.iloc[Iord,6]\n",
    "            \n",
    "    # EN CASO CONTRARIO VALORAMOS LAS POSIBLES SITUACIONES QUE DEBEMOS CONTEMPLAR.\n",
    "  \n",
    "    if (M2.iloc[Iord,2] == MATa) and (M2.iloc[Iord,3] <3) and (M2.iloc[Iord,39] >= 1) and DC == 0:\n",
    "        # GRABAMOS REGISTRO RESUMEN\n",
    "        RUTAS=RUTAS.append({'MTR' : MATa , 'FECHA_HORAsalida' : TMPa , 'LATorigen' : LATa ,'LONGorigen' : LONGa ,\\\n",
    "        'FECHA_HORAllegada' : M2.iloc[Iord,9] , 'LATdestino' : M2.iloc[Iord,5],'LONGdestino' : M2.iloc[Iord,7],\\\n",
    "        'DIRECCsalida' : '','DIRECCllegada' : '','LATLONGs' : '','LATLONGll' : '','NRUTA' : 0,'DCRUTA' : 0 } ,\\\n",
    "        ignore_index=True) \n",
    "        # REGULARIZAMOS NUEVAS VARIABLES COMO ORIGEN PROXIMA RUTA SI COINCIDE LA MATRICULA\n",
    "        MATa = M2.iloc[Iord,2]\n",
    "        TMPa = M2.iloc[Iord,9]\n",
    "        LATa = M2.iloc[Iord,5]\n",
    "        LONGa = M2.iloc[Iord,7]\n",
    "    \n",
    "    if  M2.iloc[Iord,40] >= 1 and DC == 0:\n",
    "        \n",
    "        # Retrocedemos una linea.\n",
    "        \n",
    "        Iord = Iord - 1\n",
    "        \n",
    "        # ANTES DEBEMOS GRABAR RUTA FINAL\n",
    "        RUTAS=RUTAS.append({'MTR' : MATa , 'FECHA_HORAsalida' : TMPa , 'LATorigen' : LATa ,'LONGorigen' : LONGa ,\\\n",
    "        'FECHA_HORAllegada' : M2.iloc[Iord,9] , 'LATdestino' : M2.iloc[Iord,5],'LONGdestino' : M2.iloc[Iord,7],\\\n",
    "        'DIRECCsalida' : '','DIRECCllegada' : '','LATLONGs' : '','LATLONGll' : '','NRUTA' : 0,'DCRUTA' : 0 } ,\\\n",
    "        ignore_index=True) \n",
    "       \n",
    "        # RESETEAMOS VARIABLES\n",
    "        # Nos ubicamos en la línea siguiente.\n",
    "        Iord = Iord + 1\n",
    "        # REGULARIZAMOS NUEVAS VARIABLES COMO ORIGEN PROXIMA RUTA SI COINCIDE LA MATRICULA\n",
    "        MATa = M2.iloc[Iord,2]\n",
    "        TMPa = M2.iloc[Iord,9]\n",
    "        LATa = M2.iloc[Iord,5]\n",
    "        LONGa = M2.iloc[Iord,7]\n",
    "        \n",
    "    \n",
    "    # Avanzamos registro.\n",
    "    DC = 0\n",
    "    Iord = Iord + 1\n",
    "    Tr = Tr + 1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Lineas de control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (Iord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUTAS.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUTAS.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Finalmente los resultados se acumulan en unos archivos csv con objeto de ser utilzados (y evitar consumo computacional) si fuese preciso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUTAS.to_csv( 'RUTAST0g.csv' )        \n",
    "M2.to_csv('DESARROLLO_RUTAST0.csv')\n",
    "gc.collect()\n",
    "print ('Proceso concluido')\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea (C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comenzamos el nuevo código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VARIABLES CONTROL Y DESARROLLO\n",
    "\n",
    "# CONTADOR RUTA\n",
    "CR = 0\n",
    "\n",
    "# CONTADOR POSICION DENTRO DE LA RUTA\n",
    "CPS = 0\n",
    "\n",
    "# VARIOS \n",
    "\n",
    "DC = 0\n",
    "A = 0\n",
    "Iord = 0 # Esta variable controlará la elección de filas del dataframe M2.\n",
    "Iordd = 0 # Esta variable controlará la elección de filas del dataframe RUTAS\n",
    "Tr = 1\n",
    "\n",
    "# COMIENZO ANALISIS\n",
    "\n",
    "CR = CR + 1\n",
    "\n",
    "while Tr <= len(RUTAS.index):\n",
    "    \n",
    "    while A < 1:\n",
    "        \n",
    "        if (RUTAS.iloc[Iordd,0] == M2.iloc[Iord,2])  and \\\n",
    "        (M2.iloc[Iord,9] <= RUTAS.iloc[Iordd,6]):\n",
    "            \n",
    "            M2.at[Iord,'NRUTA'] = CR\n",
    "            M2.at[Iord,'POSICION'] = CPS    \n",
    "            \n",
    "        if len(M2.index) == Iord or (RUTAS.iloc[Iordd,0] != M2.iloc[Iord,2]) or (M2.iloc[Iord,9] > RUTAS.iloc[Iordd,6]) :\n",
    "            \n",
    "            A = 1\n",
    "         \n",
    "        else:\n",
    "            \n",
    "            CPS = CPS + 1\n",
    "            Iord = Iord + 1 \n",
    "        \n",
    "    \n",
    "    # Modificamos registro de RUTAS y avanzamos.\n",
    "    \n",
    "    RUTAS.at[Iordd,'NRUTA'] = CR\n",
    "    A = 0\n",
    "    CR = CR + 1\n",
    "    CPS = 0\n",
    "    Iordd = Iordd + 1   \n",
    "    Tr = Tr + 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Finalmente los resultados se acumulan en unos archivos csv con objeto de ser utilzados (y evitar consumo computacional) si fuese preciso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M2.to_csv('DESARROLLO_RUTAST1.csv') \n",
    "RUTAS.to_csv ('RUTAST1g.csv')\n",
    "gc.collect()\n",
    "print ('Proceso concluido')  \n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea (D)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Inicio código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cumplimentamos las variables que tendremos que utilizar para GEOPY\n",
    "\n",
    "RUTAS['LATLONGs'] = RUTAS ['LATorigen'].astype(str)+','+ RUTAS ['LONGorigen'].astype(str)\n",
    "RUTAS['LATLONGll'] = RUTAS ['LATdestino'].astype(str)+','+ RUTAS ['LONGdestino'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install geopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "geolocator = Nominatim(user_agent = 'TFM')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUTAS['DIRECCsalida'] = RUTAS['LATLONGs'].apply(lambda x : geolocator.reverse(x).raw ['address'])\n",
    "RUTAS['DIRECCllegada'] = RUTAS['LATLONGll'].apply(lambda x : geolocator.reverse(x).raw ['address'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "RUTAS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparamos la información que debemos trasladar a DIRECCsalida, conteniendo el código de provincia, la comunidad y el pais.\n",
    "a = len(RUTAS.index)\n",
    "x=1\n",
    "Iord = 0\n",
    "while x <= a:\n",
    "    try:\n",
    "        b = RUTAS['DIRECCsalida'][Iord]['country']\n",
    "    except KeyError: \n",
    "        b=\"\"\n",
    "    try:\n",
    "        b1 = RUTAS['DIRECCsalida'][Iord]['state']\n",
    "    except KeyError: \n",
    "        b1=\"\"\n",
    "    try:\n",
    "        b2 = RUTAS['DIRECCsalida'][Iord]['postcode']\n",
    "    except KeyError: \n",
    "        b2=\"\"    \n",
    "    RUTAS.at[Iord,'DIRECCsalida']=b2+'/'+b+','+b1\n",
    "    Iord = Iord + 1\n",
    "    x = x +1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparamos la información que debemos trasladar a DIRECCllegada, conteniendo el código de provincia, la comunidad y el pais.\n",
    "a = len(RUTAS.index)\n",
    "x=1\n",
    "Iord = 0\n",
    "while x <= a:\n",
    "    try:\n",
    "        b = RUTAS['DIRECCllegada'][Iord]['country']\n",
    "    except KeyError: \n",
    "        b=\"\"\n",
    "    try:\n",
    "        b1 = RUTAS['DIRECCllegada'][Iord]['state']\n",
    "    except KeyError: \n",
    "        b1=\"\"\n",
    "    try:\n",
    "        b2 = RUTAS['DIRECCllegada'][Iord]['postcode']\n",
    "    except KeyError: \n",
    "        b2=\"\"    \n",
    "    RUTAS.at[Iord,'DIRECCllegada']=b2+'/'+b+','+b1\n",
    "    Iord = Iord + 1\n",
    "    x = x +1\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Finalmente los resultados se acumulan en unos archivos csv con objeto de ser utilzados (y evitar consumo computacional) si fuese preciso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUTAS.to_csv ('RUTAST2gbc.csv')\n",
    "gc.collect()\n",
    "print ('Proceso concluido')  \n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea (E)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo primero que debemos hacer es crear un nuevo dataframe para proceder a las agrupaciones de las rutas, y poder confeccionar el ranking de las rutas más habituales, indicando el DCRUTA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leemos RUTAS para evitar consumo computacional.\n",
    "M2 = pd.read_csv('DESARROLLO_RUTAST1.csv')\n",
    "RUTAS = pd.read_csv('RUTAST2gbc.csv')\n",
    "del(M2['Unnamed: 0'])\n",
    "del(RUTAS['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUTAS['FECHA_HORAsalida'] = pd.to_datetime(RUTAS['FECHA_HORAsalida'])\n",
    "RUTAS['FECHA_HORAllegada'] = pd.to_datetime(RUTAS['FECHA_HORAllegada'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREAMOS EL DATAFRAME A TRAVÉS DE UN FILTRO DE RUTAS\n",
    "\n",
    "RUTASagr =  RUTAS.filter(items=['DIRECCsalida','DIRECCllegada'])  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUTASagr['DIRECCsalida'] = RUTASagr['DIRECCsalida'] .astype(str)\n",
    "RUTASagr['DIRECCllegada'] = RUTASagr['DIRECCllegada'] .astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUTAS.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUTASagr.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUTASagr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUTASagr = RUTASagr.groupby( [ 'DIRECCsalida','DIRECCllegada'] )\n",
    "\n",
    "MRUTAS =pd.DataFrame(RUTASagr.size().reset_index(name = 'Count'))\n",
    "\n",
    "# El campo Count contabilizará las veces que se repite dicha ruta, y posteriormente se ordena de forma descendente por el\n",
    "# campo Count.\n",
    "\n",
    "MRUTAS.sort_values(['Count'],ascending = False, inplace = True)\n",
    "\n",
    "# Como el index está un pelín descolocado, lo reseteamos.\n",
    "\n",
    "MRUTAS = MRUTAS.reset_index()\n",
    "del MRUTAS['index']\n",
    "\n",
    "# Creamos otro campo, donde normalizar el ranking.\n",
    "\n",
    "MRUTAS['DCRUTAS']=0\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MRUTAS.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MRUTAS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Iord = 0 # Esta variable controlará la elección de filas del dataframe RUTAS.\n",
    "Tr = 1 # Esta variable controlará el bucle de filas del dataframe RUTAS.\n",
    "F = 1 # Esta variable controlará el valor de DCRUTA\n",
    "Fa = 1 # Esta variable controlará la evolución de Count\n",
    "A=0\n",
    "# INICIO CODIGO\n",
    "\n",
    "while Tr <= len(MRUTAS.index):\n",
    "    if A == 0:\n",
    "        A=1\n",
    "        MRUTAS.iloc[Iord,3] = Tr \n",
    "        Fa = MRUTAS.iloc[Iord,2]\n",
    "    else:\n",
    "        if Fa == MRUTAS.iloc[Iord,2]:\n",
    "            MRUTAS.iloc[Iord,3] = F \n",
    "            Fa = MRUTAS.iloc[Iord,2]\n",
    "        else:\n",
    "            F=F+1\n",
    "            MRUTAS.iloc[Iord,3] = F\n",
    "            Fa = MRUTAS.iloc[Iord,2]\n",
    "        \n",
    "    Iord = Iord+1\n",
    "    Tr = Tr+1\n",
    "\n",
    "gc.collect()\n",
    "print ('proceso concluido') \n",
    "print(datetime.datetime.now())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MARCAMOS RUTAS SEGÚN SU RANKING\n",
    "\n",
    "Iord = 0 # Esta variable controlará la elección de filas del dataframe RUTAS.\n",
    "Tr = 1 # Esta variable controlará el bucle de filas del dataframe RUTAS.\n",
    "\n",
    "Iordd = 0 # Esta variable controlará la elección de filas del dataframe MRUTAS.\n",
    "Trd = 1 # Esta variable controlará el bucle de filas del dataframe MRUTAS.\n",
    "\n",
    "B=0\n",
    "\n",
    "# INICIO CODIGO\n",
    "\n",
    "while Tr <= len(RUTAS.index):\n",
    "    Iordd = 0\n",
    "    Trd = 1\n",
    "    while Trd <= len(MRUTAS.index):\n",
    "        if ((MRUTAS.iloc[Iordd,0] == RUTAS.iloc[Iord,7])  and\\\n",
    "            (MRUTAS.iloc[Iordd,1] == RUTAS.iloc[Iord,8])): \n",
    "            \n",
    "            RUTAS.iloc[Iord,12] = MRUTAS.iloc[Iordd,3]\n",
    "            \n",
    "            \n",
    "        Iordd = Iordd + 1 \n",
    "        Trd = Trd + 1\n",
    "     \n",
    "    \n",
    "    Iord = Iord + 1\n",
    "    Tr = Tr + 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Finalmente los resultados se acumulan en unos archivos csv con objeto de ser utilzados (y evitar consumo computacional) si fuese preciso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUTAS.to_csv ('RUTAST3g.csv')  \n",
    "MRUTAS.to_csv ('MRUTAST0g.csv')\n",
    "gc.collect()\n",
    "print ('proceso concluido')\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea (F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lo primero creamos un dataframe donde el NRUTA sera distinto a 0, para trabajar sobre él.\n",
    "M2bis = M2\n",
    "M2bis = M2bis.drop(M2bis[M2bis['POSICION']==0].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINICIÓN VARIABLE COMPOSICIÓN DATASET\n",
    "# Para todos el nexo de unión será la ruta.\n",
    "\n",
    "# CONDUCTORES\n",
    "# Cuantos conductores han estado asignados a cada ruta.(GBcond).\n",
    "\n",
    "GBcond= M2bis.groupby(by='NRUTA', as_index=False).agg({'COND': pd.Series.nunique})\n",
    "GBcond= GBcond.drop_duplicates()\n",
    "\n",
    "# Para todos el nexo de unión será la ruta\n",
    "\n",
    "# Tipo de situaciones en cada ruta, y tiempo acumulado de las mismas. implicados en cada ruta GBmat\n",
    "GBcs = M2bis[['NRUTA','CS','TIME_HRS']] \n",
    "GBcs0 = GBcs.groupby( [ 'NRUTA','CS'] )\n",
    "GBcs['CShrssum'] =GBcs0['TIME_HRS'].transform(\"sum\")\n",
    "GBcs['CShrsmean'] =GBcs0['TIME_HRS'].transform(\"mean\")\n",
    "GBcs['CSrept'] =GBcs0['CS'].transform(\"count\")\n",
    "\n",
    "# Generamos dataset con CS tipo 1\n",
    "GBcs1 = GBcs[(GBcs['CS'] == 1)]\n",
    "GBcs1 = GBcs1[['NRUTA','CS','CShrssum','CShrsmean','CSrept']]\n",
    "GBcs1.rename(columns={'CS': 'CS1','CShrssum':'CS1hrssum','CShrsmean':'CS1hrsmean','CSrept':'CS1rept'}, inplace=True)\n",
    "GBcs1= GBcs1.drop_duplicates()\n",
    "\n",
    "# Generamos dataset con CS tipo 2\n",
    "GBcs2 = GBcs[(GBcs['CS'] == 2)]\n",
    "GBcs2 = GBcs2[['NRUTA','CS','CShrssum','CShrsmean','CSrept']]\n",
    "GBcs2.rename(columns={'CS': 'CS2','CShrssum':'CS2hrssum','CShrsmean':'CS2hrsmean','CSrept':'CS2rept'}, inplace=True)         \n",
    "GBcs2= GBcs2.drop_duplicates()\n",
    "\n",
    "# Generamos dataset con CS tipo 3             \n",
    "GBcs3 = GBcs[(GBcs['CS'] == 3)]\n",
    "GBcs3 = GBcs3[['NRUTA','CS','CShrssum','CShrsmean','CSrept']]\n",
    "GBcs3.rename(columns={'CS': 'CS3','CShrssum':'CS3hrssum','CShrsmean':'CS3hrsmean','CSrept':'CS3rept'}, inplace=True)         \n",
    "GBcs3= GBcs3.drop_duplicates()\n",
    "\n",
    "# Acumulado variables restantes. Se realizara un promedio de cada una de ella.\n",
    "\n",
    "GBrv = M2bis[['NRUTA','ALTa', 'ALTc', 'VELCa', 'HMa', 'HMc','CCa', 'CCc', 'TMa', 'RPMa','NFa', 'FRNa', 'FRNc',\\\n",
    "        'TRa', 'TRc', 'PMa', 'PMc','PDLa','PDLc', 'EMBa', 'EMBc']]\n",
    "\n",
    "GBrv0 = GBrv.groupby( [ 'NRUTA' ] )\n",
    "\n",
    "# Asignamos promedios\n",
    "\n",
    "cols = ['VELCa', 'TMa', 'RPMa','NFa','TRa']\n",
    "\n",
    "for c in cols:\n",
    "    GBrv[c] = GBrv0[c].transform(\"mean\")\n",
    "    \n",
    "# Asignamos valores iniciales.\n",
    "\n",
    "cols = ['ALTa', 'HMa','FRNa','PMa', 'PDLa', 'EMBa']\n",
    "\n",
    "for c in cols:\n",
    "    GBrv[c] = GBrv0[c].transform(\"first\")\n",
    "\n",
    "GBrv['CCa'] = GBrv0['CCa'].transform(\"sum\")\n",
    "\n",
    "# Asignamos valores finales.\n",
    "\n",
    "cols = ['ALTc', 'HMc','FRNc','PMc', 'PDLc', 'EMBc']\n",
    "\n",
    "for c in cols:\n",
    "    GBrv[c] = GBrv0[c].transform(\"last\")\n",
    "\n",
    "GBrv['CCc'] = GBrv0['CCc'].transform(\"count\") \n",
    "\n",
    "GBrv= GBrv.drop_duplicates()\n",
    "\n",
    "GBrv['ALTf'] = GBrv['ALTc']-GBrv['ALTa']\n",
    "GBrv['HMf'] = GBrv['HMc']-GBrv['HMa']\n",
    "GBrv['CCf'] = (GBrv['CCa']/GBrv['CCc'])\n",
    "GBrv['FRNf'] = GBrv['FRNc']-GBrv['FRNa'] # Este valor se entendería como porcentaje.\n",
    "GBrv['PMf'] = GBrv['PMc']-GBrv['PMa']\n",
    "GBrv['PDLf'] = GBrv['PDLc']-GBrv['PDLa']\n",
    "GBrv['EMBf'] = GBrv['EMBc']-GBrv['EMBa']\n",
    "\n",
    "GBrv = GBrv[['NRUTA','ALTf', 'VELCa', 'HMf','CCf', 'TMa', 'RPMa','NFa', 'FRNf',\\\n",
    "        'TRa', 'PMf','PDLf', 'EMBf']]\n",
    "\n",
    "GBrv= GBrv.drop_duplicates()\n",
    "\n",
    "# Manipulamos las variables que mantuvimos como float. ODO (odómetro) y CT (consumo total), estableciendo valor inicial y valor final.\n",
    "\n",
    "GBvp = M2bis[['NRUTA','ODOa', 'ODOc', 'CTa','CTc']]\n",
    "GBvp0 = GBvp.groupby(['NRUTA'])\n",
    "GBvp['ODOa'] =GBvp0['ODOa'].transform(\"first\")\n",
    "GBvp['ODOc'] =GBvp0['ODOc'].transform(\"last\")\n",
    "GBvp['CTa'] =GBvp0['CTa'].transform(\"first\")\n",
    "GBvp['CTc'] =GBvp0['CTc'].transform(\"last\")\n",
    "GBvp= GBvp.drop_duplicates()\n",
    "GBvp['ODOf'] = GBvp['ODOc']-GBvp['ODOa']\n",
    "GBvp['CTf'] = GBvp['CTc']-GBvp['CTa']\n",
    "GBvp = GBvp[['NRUTA','ODOa', 'ODOc','ODOf','CTa','CTc','CTf']]\n",
    "GBvp= GBvp.drop_duplicates()\n",
    "\n",
    "# Por último manipulamos las coordenadas geográficas, y los timestamp.\n",
    "\n",
    "GBfin = M2bis[['NRUTA','LATa','LONGa','LATc','LONGc','TMPa','TMPc','MTR']] \n",
    "GBfin0 = GBfin.groupby(['NRUTA'])\n",
    "GBfin['LATa'] =GBfin0['LATa'].transform(\"first\")\n",
    "GBfin['LONGa'] =GBfin0['LONGa'].transform(\"first\")\n",
    "GBfin['LATc'] =GBfin0['LATc'].transform(\"last\")\n",
    "GBfin['LONGc'] =GBfin0['LONGc'].transform(\"last\")\n",
    "GBfin['TMPa'] =GBfin0['TMPa'].transform(\"first\")\n",
    "GBfin['TMPc'] =GBfin0['TMPc'].transform(\"last\")\n",
    "GBfin= GBfin.drop_duplicates()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finalmente unimos todos los datasets para generar el dataset final optimo para modelizar.\n",
    "\n",
    "MAESTRO_RUTAS = pd.merge(GBfin,GBcond, on = 'NRUTA')\n",
    "MAESTRO_RUTAS = pd.merge(MAESTRO_RUTAS,GBcs1, on ='NRUTA')\n",
    "MAESTRO_RUTAS = pd.merge(MAESTRO_RUTAS,GBcs2, on = 'NRUTA')\n",
    "MAESTRO_RUTAS = pd.merge(MAESTRO_RUTAS,GBcs3 , on = 'NRUTA')\n",
    "MAESTRO_RUTAS = pd.merge(MAESTRO_RUTAS,GBvp, on = 'NRUTA')\n",
    "MAESTRO_RUTAS = pd.merge(MAESTRO_RUTAS,GBrv, on = 'NRUTA')\n",
    "MAESTRO_RUTAS = MAESTRO_RUTAS.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAESTRO_RUTAS['TMPa'] = pd.to_datetime(MAESTRO_RUTAS['TMPa'])\n",
    "MAESTRO_RUTAS['TMPc'] = pd.to_datetime(MAESTRO_RUTAS['TMPc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAESTRO_RUTAS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAESTRO_RUTAS.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAESTRO_RUTAS.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MAESTRO_RUTAS.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, añadimos una columna vital, y que nos indicará que tiempo se ha consumido en el desarrollo de la ruta (incluyendo los descansos dentro de la misma sin el camión en marcha y fuera del control de timestamp, ese valor será la columna TDsts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAESTRO_RUTAS.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAESTRO_RUTAS['days']= MAESTRO_RUTAS['TMPc']-MAESTRO_RUTAS['TMPa']\n",
    "\n",
    "# Transformamos el timedelta en horas.\n",
    "\n",
    "MAESTRO_RUTAS['TIME_RUTA'] = MAESTRO_RUTAS['days'] / np.timedelta64(1, 'h')\n",
    "del(MAESTRO_RUTAS['days'])\n",
    "MAESTRO_RUTAS['CS3hrssum'] = MAESTRO_RUTAS['CS3rept']/60\n",
    "MAESTRO_RUTAS['CS3hrsmean']=1/60\n",
    "MAESTRO_RUTAS['TDsts']= MAESTRO_RUTAS['TIME_RUTA']- (MAESTRO_RUTAS['CS1hrssum']+MAESTRO_RUTAS['CS2hrssum']\\\n",
    "+MAESTRO_RUTAS['CS3hrssum'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAESTRO_RUTAS.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAESTRO_RUTAS.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente los resultados se acumulan en unos archivos csv con objeto de ser utilzados (y evitar consumo computacional) si fuese preciso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAESTRO_RUTAS.to_csv ('MAESTRO_RUTASTg.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea (G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para todos el nexo de unión será la ruta\n",
    "\n",
    "# Tipo de situaciones en cada ruta, y tiempo acumulado de las mismas. implicados en cada ruta GBmat\n",
    "GBcs = M2Bis[['NRUTA','CS','TIME_HRS','COND']] \n",
    "GBcs0 = GBcs.groupby( [ 'NRUTA','CS','COND'] )\n",
    "GBcs['CShrssum'] =GBcs0['TIME_HRS'].transform(\"sum\")\n",
    "GBcs['CShrsmean'] =GBcs0['TIME_HRS'].transform(\"mean\")\n",
    "GBcs['CSrept'] =GBcs0['CS'].transform(\"count\")\n",
    "\n",
    "# Generamos dataset con CS tipo 1\n",
    "GBcs1 = GBcs[(GBcs['CS'] == 1)]\n",
    "GBcs1 = GBcs1[['NRUTA','CS','CShrssum','CShrsmean','CSrept','COND']]\n",
    "GBcs1.rename(columns={'CS': 'CS1','CShrssum':'CS1hrssum','CShrsmean':'CS1hrsmean','CSrept':'CS1rept'}, inplace=True)\n",
    "GBcs1= GBcs1.drop_duplicates()\n",
    "\n",
    "# Generamos dataset con CS tipo 2\n",
    "GBcs2 = GBcs[(GBcs['CS'] == 2)]\n",
    "GBcs2 = GBcs2[['NRUTA','CS','CShrssum','CShrsmean','CSrept','COND']]\n",
    "GBcs2.rename(columns={'CS': 'CS2','CShrssum':'CS2hrssum','CShrsmean':'CS2hrsmean','CSrept':'CS2rept'}, inplace=True)         \n",
    "GBcs2= GBcs2.drop_duplicates()\n",
    "\n",
    "# Generamos dataset con CS tipo 3             \n",
    "GBcs3 = GBcs[(GBcs['CS'] == 3)]\n",
    "GBcs3 = GBcs3[['NRUTA','CS','CShrssum','CShrsmean','CSrept','COND']]\n",
    "GBcs3.rename(columns={'CS': 'CS3','CShrssum':'CS3hrssum','CShrsmean':'CS3hrsmean','CSrept':'CS3rept'}, inplace=True)         \n",
    "GBcs3= GBcs3.drop_duplicates()\n",
    "\n",
    "# Acumulado variables restantes. Se realizara un promedio de cada una de ella.\n",
    "\n",
    "GBrv = M2Bis[['NRUTA','COND','ALTa', 'ALTc', 'VELCa', 'HMa', 'HMc','CCa', 'CCc', 'TMa', 'RPMa','NFa', 'FRNa', 'FRNc',\\\n",
    "        'TRa', 'TRc', 'PMa', 'PMc','PDLa','PDLc', 'EMBa', 'EMBc']]\n",
    "\n",
    "GBrv0 = GBrv.groupby( [ 'NRUTA','COND' ] )\n",
    "\n",
    "# Asignamos promedios\n",
    "\n",
    "cols = ['VELCa', 'TMa', 'RPMa','NFa','TRa']\n",
    "\n",
    "for c in cols:\n",
    "    GBrv[c] = GBrv0[c].transform(\"mean\")\n",
    "    \n",
    "# Asignamos valores iniciales.\n",
    "\n",
    "cols = ['ALTa', 'HMa','FRNa','PMa', 'PDLa', 'EMBa']\n",
    "\n",
    "for c in cols:\n",
    "    GBrv[c] = GBrv0[c].transform(\"first\")\n",
    "\n",
    "GBrv['CCa'] = GBrv0['CCa'].transform(\"sum\")\n",
    "\n",
    "# Asignamos valores finales.\n",
    "\n",
    "cols = ['ALTc', 'HMc','FRNc','PMc', 'PDLc', 'EMBc']\n",
    "\n",
    "for c in cols:\n",
    "    GBrv[c] = GBrv0[c].transform(\"last\")\n",
    "\n",
    "GBrv['CCc'] = GBrv0['CCc'].transform(\"count\") \n",
    "\n",
    "GBrv= GBrv.drop_duplicates()\n",
    "\n",
    "GBrv['ALTf'] = GBrv['ALTc']-GBrv['ALTa']\n",
    "GBrv['HMf'] = GBrv['HMc']-GBrv['HMa']\n",
    "GBrv['CCf'] = (GBrv['CCa']/GBrv['CCc'])\n",
    "GBrv['FRNf'] = GBrv['FRNc']-GBrv['FRNa'] # Este valor se entendería como porcentaje.\n",
    "GBrv['PMf'] = GBrv['PMc']-GBrv['PMa']\n",
    "GBrv['PDLf'] = GBrv['PDLc']-GBrv['PDLa']\n",
    "GBrv['EMBf'] = GBrv['EMBc']-GBrv['EMBa']\n",
    "\n",
    "GBrv = GBrv[['NRUTA','COND','ALTf', 'VELCa', 'HMf','CCf', 'TMa', 'RPMa','NFa', 'FRNf',\\\n",
    "        'TRa', 'PMf','PDLf', 'EMBf']]\n",
    "GBrv= GBrv.drop_duplicates()\n",
    "\n",
    "# Manipulamos las variables que mantuvimos como float. ODO (odómetro) y CT (consumo total), estableciendo valor inicial y valor final.\n",
    "\n",
    "GBvp = M2Bis[['NRUTA','COND','ODOa', 'ODOc', 'CTa','CTc']]\n",
    "GBvp0 = GBvp.groupby(['NRUTA','COND'])\n",
    "GBvp['ODOa'] =GBvp0['ODOa'].transform(\"first\")\n",
    "GBvp['ODOc'] =GBvp0['ODOc'].transform(\"last\")\n",
    "GBvp['CTa'] =GBvp0['CTa'].transform(\"first\")\n",
    "GBvp['CTc'] =GBvp0['CTc'].transform(\"last\")\n",
    "GBvp= GBvp.drop_duplicates()\n",
    "GBvp['ODOf'] = GBvp['ODOc']-GBvp['ODOa']\n",
    "GBvp['CTf'] = GBvp['CTc']-GBvp['CTa']\n",
    "GBvp = GBvp[['NRUTA','COND','ODOa', 'ODOc','ODOf','CTa','CTc','CTf']]\n",
    "\n",
    "# Por último manipulamos las coordenadas geográficas, y los timestamp.\n",
    "\n",
    "GBfin = M2Bis[['NRUTA','COND','LATa','LONGa','LATc','LONGc','TMPa','TMPc','MTR']] \n",
    "GBfin0 = GBfin.groupby(['NRUTA','COND'])\n",
    "GBfin['LATa'] =GBfin0['LATa'].transform(\"first\")\n",
    "GBfin['LONGa'] =GBfin0['LONGa'].transform(\"first\")\n",
    "GBfin['LATc'] =GBfin0['LATc'].transform(\"last\")\n",
    "GBfin['LONGc'] =GBfin0['LONGc'].transform(\"last\")\n",
    "GBfin['TMPa'] =GBfin0['TMPa'].transform(\"first\")\n",
    "GBfin['TMPc'] =GBfin0['TMPc'].transform(\"last\")\n",
    "GBfin= GBfin.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finalmente unimos todos los datasets para generar el dataset final optimo para modelizar.\n",
    "\n",
    "MAESTRO_RUTASxcond = pd.merge(GBfin,GBcs1, on=['NRUTA', 'COND'])\n",
    "MAESTRO_RUTASxcond = pd.merge(MAESTRO_RUTASxcond,GBcs2, on=['NRUTA', 'COND'])\n",
    "MAESTRO_RUTASxcond = pd.merge(MAESTRO_RUTASxcond,GBcs3, on=['NRUTA', 'COND'])\n",
    "MAESTRO_RUTASxcond = pd.merge(MAESTRO_RUTASxcond,GBvp, on=['NRUTA', 'COND'])\n",
    "MAESTRO_RUTASxcond = pd.merge(MAESTRO_RUTASxcond,GBrv, on=['NRUTA', 'COND'])\n",
    "MAESTRO_RUTASxcond = MAESTRO_RUTASxcond.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAESTRO_RUTASxcond['TMPa'] = pd.to_datetime(MAESTRO_RUTASxcond['TMPa'])\n",
    "MAESTRO_RUTASxcond['TMPc'] = pd.to_datetime(MAESTRO_RUTASxcond['TMPc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAESTRO_RUTASxcond['days']= MAESTRO_RUTASxcond['TMPc']-MAESTRO_RUTASxcond['TMPa']\n",
    "# Transformamos el timedelta en horas.\n",
    "MAESTRO_RUTASxcond['TIME_RUTA'] = MAESTRO_RUTASxcond['days'] / np.timedelta64(1, 'h')\n",
    "del(MAESTRO_RUTASxcond['days'])\n",
    "MAESTRO_RUTASxcond['CS3hrssum'] = MAESTRO_RUTASxcond['CS3rept']/60\n",
    "MAESTRO_RUTASxcond['CS3hrsmean']=1/60\n",
    "MAESTRO_RUTASxcond['TDsts']= MAESTRO_RUTASxcond['TIME_RUTA']- (MAESTRO_RUTASxcond['CS1hrssum']\\\n",
    "+MAESTRO_RUTASxcond['CS2hrssum']+MAESTRO_RUTASxcond['CS3hrssum'])\n",
    "MAESTRO_RUTASxcond = MAESTRO_RUTASxcond.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAESTRO_RUTASxcond.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAESTRO_RUTASxcond.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Finalmente los resultados se acumulan en unos archivos csv con objeto de ser utilzados (y evitar consumo computacional) si fuese preciso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAESTRO_RUTASxcond.to_csv ('MAESTRO_RUTASTgxcond.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proceso final. Exportación datasets para modelizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M2.to_csv('DESARROLLO_RUTAST.csv') \n",
    "RUTAS.to_csv ('RUTASTg.csv')\n",
    "MRUTAS.to_csv ('MRUTASTg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datetime.datetime.now())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
